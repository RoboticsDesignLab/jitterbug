% Encoding: UTF-8



@article{SAC,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}


@article{DDPG,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{TD3,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
 }

@article{PPO,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@inproceedings{TRPO,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@inproceedings{mujoco,
  title={{MuJoCo}: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}



@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}


@inproceedings{todorov2008general,
  title={General duality between optimal control and estimation},
  author={Todorov, Emanuel},
  booktitle={IEEE Conference on Decision and Control},
  pages={4286--4292},
  year={2008},
  organization={IEEE}
}


@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S and Maei, Hamid R and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}



@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}


@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


@inproceedings{gupta2017cooperative,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  pages={66--83},
  year={2017},
  organization={Springer}
}


@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}


@article{kimura2018daqn,
  title={DAQN: Deep auto-encoder and Q-network},
  author={Kimura, Daiki},
  journal={arXiv preprint arXiv:1806.00630},
  year={2018}
}


@inproceedings{he2018amc,
  title={Amc: Automl for model compression and acceleration on mobile devices},
  author={He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={784--800},
  year={2018}
}


@inproceedings{wang2019haq,
  title={HAQ: Hardware-Aware Automated Quantization with Mixed Precision},
  author={Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8612--8620},
  year={2019}
}

@inproceedings{nagabandi2018learning,
  title={Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots},
  author={Nagabandi, Anusha and Yang, Guangzhao and Asmar, Thomas and Pandya, Ravi and Kahn, Gregory and Levine, Sergey and Fearing, Ronald S},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4606--4613},
  year={2018},
  organization={IEEE}
}


@article{clavera2018learning,
  title={Learning to adapt: Meta-learning for model-based control},
  author={Clavera, Ignasi and Nagabandi, Anusha and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1803.11347},
  volume={3},
  year={2018}
}


@inproceedings{morton2018deep,
  title={Deep dynamical modeling and control of unsteady fluid flows},
  author={Morton, Jeremy and Jameson, Antony and Kochenderfer, Mykel J and Witherden, Freddie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9258--9268},
  year={2018}
}


@article{lutter2019deep,
  title={Deep Lagrangian Networks for end-to-end learning of energy-based control for under-actuated systems},
  author={Lutter, Michael and Listmann, Kim and Peters, Jan},
  journal={arXiv preprint arXiv:1907.04489},
  year={2019}
}


@article{Hongwei.USV,
author = {Hongwei Xu and Ning Wang and Hong Zhao and Zhongjiu Zheng},
title = {Deep reinforcement learning-based path planning of underactuated surface vessels},
journal = {Cyber-Physical Systems},
volume = {5},
number = {1},
pages = {1-17},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/23335777.2018.1540018},

URL = { 
        https://doi.org/10.1080/23335777.2018.1540018
    
},
eprint = { 
        https://doi.org/10.1080/23335777.2018.1540018
    
}
,
    abstract = {This paper is dedicated to the issues of path planning for the underactuated surface vessel (USV) in unknown environments with obstacles. Aiming at the usability problem caused by the complicated control law of the traditional method, a deep deterministic policy gradient (DDPG)-based path planning algorithm is proposed with the powerful actor-critic architecture. The main contributions of this paper are as follows: (1) The DDPG-based path planning method is the decision control system of USV whose output is continuous. (2) A complete reward system is specially designed for target approaching, speed control and attitude correction. (3) Since the reward system is independent, it is highly customisable and can be changed according to the task and the control model. Through the simulation, the results show that the perfect path can be automatically generated under unknown environmental disturbance, thus providing the proposed DDPG-based path planning scheme effectiveness and applied meaning. }
}


]@inproceedings{zhang2018deep,
  title={Deep imitation learning for complex manipulation tasks from virtual reality teleoperation},
  author={Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}


@inproceedings{fan2018surreal,
  title={Surreal: Open-source reinforcement learning framework and robot manipulation benchmark},
  author={Fan, Linxi and Zhu, Yuke and Zhu, Jiren and Liu, Zihua and Zeng, Orien and Gupta, Anchit and Creus-Costa, Joan and Savarese, Silvio and Fei-Fei, Li},
  booktitle={Conference on Robot Learning},
  pages={767--782},
  year={2018}
}


@article{lynch2019learning,
  title={Learning Latent Plans from Play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:1903.01973},
  year={2019}
}


@InProceedings{Wang_ae_vision_feature_fusion,
author="Wang, Haotian
and Yang, Wenjing
and Huang, Wanrong
and Lin, Zhipeng
and Tang, Yuhua",
editor="Cheng, Long
and Leung, Andrew Chi Sing
and Ozawa, Seiichi",
title="Multi-feature Fusion for Deep Reinforcement Learning: Sequential Control of Mobile Robots",
booktitle="Neural Information Processing",
year="2018",
publisher="Springer International Publishing",
pages="303--315",
abstract="Compared with traditional motion planners, deep reinforcement learning has been applied more and more widely to achieving sequential behaviours control of mobile robots in indoor environment. However, the state of robot in deep reinforcement learning is commonly obtained through single sensor, which lacks accuracy and stability. In this paper, we propose a novel approach called multi-feature fusion framework. The multi-feature fusion framework utilizes multiple sensors to gather different scene images around the robot. Once environment information is gathered, a well-trained autoencoder achieves the fusion and extraction of multiple visual features. With more accurate and stable states extracted from the autoencoder, we train the mobile robot to patrol and navigate in 3D simulation environment with an asynchronous deep reinforcement learning algorithm. Extensive simulation experiments demonstrate that the proposed multi-feature fusion framework improves not only the convergence rate of training phase but also the testing performance of the mobile robot.",
isbn="978-3-030-04239-4"
}


@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}


@article{recht2019tour,
  title={A tour of reinforcement learning: The view from continuous control},
  author={Recht, Benjamin},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={2},
  pages={253--279},
  year={2019},
  publisher={Annual Reviews}
}


@inproceedings{james2019sim,
  title={Sim-to-real via sim-to-sim: Data-efficient robotic grasping via randomized-to-canonical adaptation networks},
  author={James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={12627--12637},
  year={2019}
}

@Article{Islam2017,
  author  = {Islam, Riashat and Henderson, Peter and Gomrokchi, Maziar and Precup, Doina},
  title   = {Reproducibility of benchmarked deep reinforcement learning tasks for continuous control},
  journal = {arXiv preprint arXiv:1708.04133},
  year    = {2017},
}

@InProceedings{Mnih2016,
  author    = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  title     = {Asynchronous methods for deep reinforcement learning},
  booktitle = {International conference on machine learning},
  year      = {2016},
  pages     = {1928--1937},
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Kingsbury, Brian and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  year={2012}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@inproceedings{hester2013open,
  title={The open-source TEXPLORE code release for reinforcement learning on robots},
  author={Hester, Todd and Stone, Peter},
  booktitle={Robot Soccer World Cup},
  pages={536--543},
  year={2013},
  organization={Springer}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}


@inproceedings{bitzer2010using,
  title={Using dimensionality reduction to exploit constraints in reinforcement learning},
  author={Bitzer, Sebastian and Howard, Matthew and Vijayakumar, Sethu},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3219--3225},
  year={2010},
  organization={IEEE}
}

@inproceedings{ghadirzadeh2017deep,
  title={Deep predictive policy training using reinforcement learning},
  author={Ghadirzadeh, Ali and Maki, Atsuto and Kragic, Danica and Bj{\"o}rkman, M{\aa}rten},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2351--2358},
  year={2017},
  organization={IEEE}
}

@inproceedings{keller2006automatic,
  title={Automatic basis function construction for approximate dynamic programming and reinforcement learning},
  author={Keller, Philipp W and Mannor, Shie and Precup, Doina},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={449--456},
  year={2006},
  organization={ACM}
}


@article{ficuciello2018brief,
  title={A brief survey on the role of dimensionality reduction in manipulation learning and control},
  author={Ficuciello, Fanny and Falco, Pietro and Calinon, Sylvain},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={3},
  pages={2608--2615},
  year={2018},
  publisher={IEEE}
}


@article{AE_hinton2006reducing,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

@TechReport{ngsparse,
  author      = {Ng, Andrew},
  title       = {Sparse autoencoder},
  institution = {Stanford University},
  year        = {2011},
  type        = {CS294A Lecture Notes},
}

@article{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Feb},
  pages={625--660},
  year={2010}
}

@mastersthesis{sandven2016visual,
  title={Visual Pretraining for Deep Q-Learning},
  author={Sandven, Torstein},
  year={2016},
  school={NTNU}
}


@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}


@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}


@inproceedings{lange2010deep,
  title={Deep auto-encoder neural networks in reinforcement learning},
  author={Lange, Sascha and Riedmiller, Martin},
  booktitle={The 2010 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2010},
  organization={IEEE}
}

@inproceedings{nishimura2017thin,
  title={Thin plate manipulation by an under-actuated robotic soft gripper utilizing the environment},
  author={Nishimura, Toshihiro and Mizushima, Kaori and Suzuki, Yosuke and Tsuji, Tokuo and Watanabe, Tetsuyou},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1236--1243},
  year={2017},
  organization={IEEE}
}


@TechReport{tedrake2009underactuated,
  title={Underactuated Robotics: Learning, Planning, and Control for Efficient and Agile Machines: Course Notes for MIT 6.832},
  author={Tedrake, Russ},
  institution = {Massachusetts Institute of Technology},
  volume={3},
  year={2009}
  }

  @inproceedings{maeda2010feedback,
  title={Feedback motion planning approach for nonlinear control using gain scheduled RRTs},
  author={Maeda, Guilherme J and Singh, Surya PN and Durrant-Whyte, Hugh},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={119--126},
  year={2010},
  organization={IEEE}
}


@article{nakajima2015information,
  title={Information processing via physical soft body},
  author={Nakajima, Kohei and Hauser, Helmut and Li, Tao and Pfeifer, Rolf},
  journal={Scientific reports},
  volume={5},
  pages={10487},
  year={2015},
  publisher={Nature Publishing Group}
}


@inproceedings{maeda2014iterative,
  title={Iterative autonomous excavation},
  author={Maeda, Guilherme J and Rye, David C and Singh, Surya P N},
  booktitle={Field and service robotics},
  pages={369--382},
  year={2014},
  organization={Springer}
}


@incollection{spong1998underactuated,
  title={Underactuated mechanical systems},
  author={Spong, Mark W},
  booktitle={Control problems in robotics and automation},
  pages={135--150},
  year={1998},
  publisher={Springer}
}


@article{kelly2019dircol5i,
  title={DirCol5i: Trajectory Optimization for Problems With High-Order Derivatives},
  author={Kelly, Matthew P},
  journal={Journal of Dynamic Systems, Measurement, and Control},
  volume={141},
  number={3},
  pages={034502},
  year={2019},
  publisher={American Society of Mechanical Engineers}
}



@incollection{von1993numerical,
  title={Numerical solution of optimal control problems by direct collocation},
  author={Von Stryk, Oskar},
  booktitle={Optimal Control},
  pages={129--143},
  year={1993},
  publisher={Springer}
}


@inproceedings{kalakrishnan2011stomp,
  title={STOMP: Stochastic trajectory optimization for motion planning},
  author={Kalakrishnan, Mrinal and Chitta, Sachin and Theodorou, Evangelos and Pastor, Peter and Schaal, Stefan},
  booktitle={2011 IEEE international conference on robotics and automation},
  pages={4569--4574},
  year={2011},
  organization={IEEE}
}

@book{betts2010practical,
  title={Practical methods for optimal control and estimation using nonlinear programming},
  author={Betts, John T},
  volume={19},
  year={2010},
  publisher={{SIAM}}
}


@article{xu2016manifold,
  title={Manifold-based reinforcement learning via locally linear reconstruction},
  author={Xu, Xin and Huang, Zhenhua and Zuo, Lei and He, Haibo},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={4},
  pages={934--947},
  year={2016},
  publisher={IEEE}
}

@inproceedings{watter2015embed,
  title={Embed to control: A locally linear latent dynamics model for control from raw images},
  author={Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
  booktitle={Advances in neural information processing systems},
  pages={2746--2754},
  year={2015}
}






@Comment{jabref-meta: databaseType:bibtex;}
